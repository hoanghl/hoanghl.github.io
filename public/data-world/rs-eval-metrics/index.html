<!doctype html><html lang=en><head data-base-url=https://hoanghl.io/ data-build-search-index=true data-comments-enabled=true data-giscus-category=General data-giscus-category-id=DIC_kwDOLQ4cp84CdIjK data-giscus-crossorigin=anonymous data-giscus-emit-metadata=0 data-giscus-input-position=bottom data-giscus-lang=en data-giscus-mapping=url data-giscus-nonce data-giscus-reactions-enabled=0 data-giscus-repo=kuznetsov17/pico data-giscus-repo-id=R_kgDOLQ4cpw data-giscus-src=https://giscus.app/client.js data-giscus-strict=0><meta charset=utf-8><title>Evaluation metrics in recommender system</title><script src=https://cdnjs.cloudflare.com/ajax/libs/slideout/1.0.1/slideout.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/slideout/1.0.1/slideout.min.js></script><link crossorigin href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.css integrity=sha384-o3WH+1yEhq+grOgz1BVYTZPyTlMXrDxnjN1By9/ba94JqJhva6wFm2Hb+URQX53v rel=stylesheet><script crossorigin defer integrity=sha384-C5yZTsgLOfuizO9kb+hrB8uSBwwvZ4yenKWU0KmWl+7bkL6Tph/KbcOa3S4zdoRE src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.js></script><script crossorigin defer integrity=sha384-zWYbd0NBwgTsgIdFKVprSfTh1mbMPe5Hz1X3yY4Sd1h/K1cQoUe36OGwAGz/PcDy src=https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/mathtex-script-type.min.js></script><script crossorigin defer integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh onload=renderMathInElement(document.body); src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js></script><link href=https://hoanghl.io/site.css rel=stylesheet><link crossorigin href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.css integrity=sha384-o3WH+1yEhq+grOgz1BVYTZPyTlMXrDxnjN1By9/ba94JqJhva6wFm2Hb+URQX53v rel=stylesheet><meta content="Some Description" name=description><meta content="Hoang Le" name=author><meta content=data,machine-learning,recommender-system,evaluation name=keywords><link href="https://hoanghl.io/css/grid.css?v=29062025103816" rel=stylesheet><link href="https://hoanghl.io/css/style.css?v=29062025103816" rel=stylesheet><link href=https://hoanghl.io/images/letter.jpg rel=icon type=image/png><link href=https://hoanghl.io/images/letter.jpg rel=mask-icon type=image/png><script src="https://hoanghl.io/js/codecopy.js?v=29062025103816"></script><script src="https://hoanghl.io/js/mermaid.min.js?v=29062025103816"></script><script src="https://hoanghl.io/elasticlunr.min.js?v=29062025103816"></script><script src="https://hoanghl.io/js/search.js?v=29062025103816"></script><body><header><div class=container id=header-container><div class=row><div class=col-2></div><div class=col-8 id=top><div id=menu><ul><li><a href=https://hoanghl.io/>home</a><li><a href=https://hoanghl.io/programming>programming</a><li><a class=active href=https://hoanghl.io/data-world>data-world</a></ul></div><div id=searchBox><span class="icon icon-search head"></span><input id=searchInput name=search></div><span class="icon head" id=cIcon></span></div><div class=col-2></div></div></div></header><div class=row><div class=col-12><div id=sResults><ul class=search-results id=sResultsUL></ul></div></div></div><main><div class=container id=main-container><div class=row><div class=col-2></div><div class="col-8 content"><h1 class=center>Evaluation metrics in recommender system</h1><span class=post-tags> <ul><li><a class=singlepost-tags href=https://hoanghl.io/tags/ml/>#ml</a> <li><a class=singlepost-tags href=https://hoanghl.io/tags/recommender-system/>#recommender-system</a> </ul> </span><div><details><summary><span class=toc-header>Contents</span></summary> <ul class=toc><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#definition-of-relevance>Definition of Relevance</a><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#accuracy-based-metrics>Accuracy based metrics</a> <ul class=toc><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#1-mse>1. MSE</a><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#2-rmse>2. RMSE</a></ul><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#decision-support-metrics>Decision support metrics</a> <ul class=toc><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#1-precision-k>1. Precision@k</a><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#2-recall-k>2. Recall@k</a></ul><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#ranking-based-metrics>Ranking-based metrics</a> <ul class=toc><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#1-ncdg>1. NCDG</a><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#2-mean-average-precision-at-k-map-k>2. Mean Average Precision at k (MAP@k)</a><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#3-mean-reciprocal-rank-at-k-mrr-k>3. Mean Reciprocal Rank at k (MRR@k)</a><li class=toc><a href=https://hoanghl.io/data-world/rs-eval-metrics/#4-hit-rate-at-k>4. Hit Rate at k</a></ul></ul></details><h1 id=definition-of-relevance>Definition of Relevance</h1><p>The relevance is indicated either by:<ul><li>binary value: 1 → like ; 0 → not like<li>setting a threshold for non-binary values: given the possible rates are [1, 2…5], all values greater than 3 is considered relevant</ul><p>Hereafter, the term relevant and positive are used interchangeably.<h1 id=accuracy-based-metrics>Accuracy based metrics</h1><p>Accuracy based metrics usually require non-binary outputs.<h2 id=1-mse>1. MSE</h2><p>Denote:<ul><li>\( y_{ui} \): groundtruth rate by user \( u \) to item \( i \)<li>\( y_{ui} \): predicted rate by user \( u \) to item \( i \)</ul><p>$$ MSE = \dfrac{1}{\mathcal{D}} \sum_{(u, i) \in \mathcal{D}} \big( y_{ui} - \hat{y}_{ui} \big)^2 $$<p>This metric requires no negative sample.<h2 id=2-rmse>2. RMSE</h2><p>RMSE is intrinsically a square root of MSE<p>$$ RMSE = \sqrt{\dfrac{1}{\mathcal{D}} \sum_{(u, i) \in \mathcal{D}} \big( y_{ui} - \hat{y}_{ui} \big)^2} $$<h1 id=decision-support-metrics>Decision support metrics</h1><p>Unlike accuracy based metrics, decision support ones can work with either binary or non-binary outputs because they rely on the idea of relevance.<figure><img src=res/decision_support.jpeg style=width:100%><figcaption></figcaption></figure><h2 id=1-precision-k>1. Precision@k</h2><p>The evaluation process is as follow:<ol><li>For each user in the test set, you have $M$ items, and out of them, there are $N$ positive items.<li>You forward these $M$ items into model $f_\theta$ to calculate the corresponding scores.<li>You sort these $M$ items w.r.t. their score and take \( k \) first items</ol><p>Precision@k is then calculated as follow:<p>$$ Precision@k = \dfrac{N_k}{k} $$<p>where:<ul><li>\( N_k \) indicates the number of positive items appearing in the list of \( k \) first items</ul><h2 id=2-recall-k>2. Recall@k</h2><p>The process of calculating Recall@k is similar to that of Precision@k. The difference lays on the formula.<p>$$ Recall@k = \dfrac{N_k}{N} $$<p>This definition implies that the Recall@k won’t never reach its perfect value (i.e. \( 1 \) ) unless \( k \geq N \).<h1 id=ranking-based-metrics>Ranking-based metrics</h1><h2 id=1-ncdg>1. NCDG</h2><ul><li>Each testing item has target score (gain): <ul><li>With explicit feedback: the gain is the rating the user gives to the item<li>With implicit feedback: the gain is 1 indicating the user interacts with the item</ul><li>Negative samples are items with which the user never interacts.<li>The model gives a score (so-called <strong>predicted score</strong>) for every user-item pair (including groundtruth pair and negative pairs) → The items are later sorted w.r.t the ascending order of the predicted scores. This score can be the value before/after sigmoid function (in BCELoss), before/after softmax function (in CrossEntropyLoss)</ul><p>The formula is as follow:<p>$$ nDCG@k = \dfrac{DCG@k}{IDCG@k} $$<p>where:<p>$$ DCG@k = \sum_{i=1}^k \dfrac{gain_i}{\log_2(i+1)} $$<p>and<p>$$ IDCG@k = \sum_{i=1}^k \dfrac{gain_i}{\log_2(i+1)} $$<p>Note that IDCG is similar with DCG but the items are in ideal order, i.e. the relevant item is placed 1st, and the negative items are in following. In addition, in the case of implicit feedback, the formula of DCG@k (so does with IDCG@k) can be written as follow:<p>$$ DCG@k = \sum_{i=1}^k \dfrac{rel(i)}{\log_2(i+1)} $$<p>where:<ul><li>\( rel(i) = \Bbb{1}_\text{item \( i \) is relevant} \)</ul><p>The following flowchart describes setps to calculate nDCG@k in recommendation with implicit feedback case.<figure><img src=res/ndcg_flowchart.jpeg style=width:100%><figcaption></figcaption></figure><p>In such case,<p>$$ DCG@k = \dfrac{0}{\log_2(0+1)} + \dfrac{0}{\log_2(1+1)} + \dfrac{1}{\log_2(2+1)} + \dfrac{0}{\log_2(3+1)} + \dfrac{0}{\log_2(4+1)} $$<p>and<p>$$ IDCG@k = \dfrac{1}{\log_2(0+1)} + \dfrac{0}{\log_2(1+1)} + \dfrac{0}{\log_2(2+1)} + \dfrac{0}{\log_2(3+1)} + \dfrac{0}{\log_2(4+1)} $$<p>Although nDCG@k can be used in both cases when the gain is either binary or not, for binary gain case, it is recommended to used MAP@k.<h2 id=2-mean-average-precision-at-k-map-k>2. Mean Average Precision at k (MAP@k)</h2><p>MAP@k leverages Precision@k to ranking-aware metrics’s world.<p>Denote:<ul><li>\( U \): set of users within the test set<li>\( N_u \): no. relevant items of user \( u \) in test set<li>\( rel(i) = \Bbb{1}_\text{item \( i \) is relevant} \)<li>\( \big( AP@k \big)_u \): Average Precision at \( k \) of user \( u \)</ul><p>Then, Average Precision at \( k \) (AP@k) is calculated is as follow:<p>$$ AP@k = \dfrac{1}{N_u} \sum_{i=1}^k Precision@i \times rel(i) $$<p>MAP@k is therefore calculated as follow:<p>$$ MAP@k = \dfrac{1}{|U|} \sum_{u \in U} \big( AP@k \big)_u $$<h2 id=3-mean-reciprocal-rank-at-k-mrr-k>3. Mean Reciprocal Rank at k (MRR@k)</h2><p>Reciprocal Rank refers to the rank of the first relevant item within the first \( k \) items, and Mean Reciprocal Rank averages the Reciprocal Rank at k of all users.<p>Denote:<ul><li>\( rank_u \): rank of the first relevant item in first \( k \) items of user \( u \)</ul><p>Then, MRR@k is calculated as follow:<p>$$ MRR@k = \dfrac{1}{|U|} \sum_{u \in U} \dfrac{1}{rank_u} $$<h2 id=4-hit-rate-at-k>4. Hit Rate at k</h2><p>Hit Rate at k estimates the average number of users who have the relevant item appearing in first \( k \) items. The formula is as follow:<p>$$ HR@k = \dfrac{1}{|U|} \sum_{u \in U} \Bbb{1}_{\text{relevant item appears in first \( k \) items}} $$</div></div><div class=col-2></div></div><div class="row postnav"><div class=col-2></div><div class=col-8><div class="col-6 left"></div><div class="col-6 right"><a class=postnav href=https://hoanghl.io/data-world/rs-loss/>Recommender system loss functions →</a></div></div><div class=col-2></div></div></div><div class=row><div class=col-2></div><div class=col-8 id=giscusWidget></div></div></main><script src="https://hoanghl.io/js/colortheme.js?v=29062025103816"></script><script src="https://hoanghl.io/js/init.js?v=29062025103816"></script>